{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 26 14:48:39 2022\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import ensemble,gaussian_process,linear_model,naive_bayes,neighbors,svm,tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, roc_auc_score, precision_score, recall_score, auc, classification_report, precision_recall_curve\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns\n",
    "\n",
    "df_airports = pd.read_csv('airports.csv')\n",
    "df_hdata = pd.read_csv('historic_data.csv', low_memory=False)\n",
    "df_future = pd.read_csv('future_data.csv', low_memory=False)\n",
    "# preprocesing\n",
    "\n",
    "\n",
    "feature_hd, feature_fd = featureEngineeringCancellation(df_hdata, df_future, df_airports)\n",
    "\n",
    "\n",
    "df_cat =feature_hd.groupby('CANCELLED', group_keys=False).apply(lambda x: x.sample(frac=0.20))\n",
    "\n",
    "#Counter(df_cat.CANCELLED)\n",
    "\n",
    "\n",
    "\n",
    "df_model1 = df_cat[['AIRLINE','FLIGHT_NUMBER','TAIL_NUMBER','ORIGIN_AIRPORT','DESTINATION_AIRPORT','DISTANCE','OR_CITY','OR_STATE',\n",
    "                    'OR_LATITUDE','OR_LONGITUDE','DES_CITY','DES_STATE','DES_LATITUDE','DES_LONGITUDE','DAY_DE','WEEKDAY_DE',\n",
    "                    'WEEKEND_DE','HOUR_DE','HOUR_AR','CANCELLED']]\n",
    "\n",
    "df_futurefd = feature_fd[['AIRLINE','FLIGHT_NUMBER','TAIL_NUMBER','ORIGIN_AIRPORT','DESTINATION_AIRPORT','DISTANCE','OR_CITY','OR_STATE',\n",
    "                    'OR_LATITUDE','OR_LONGITUDE','DES_CITY','DES_STATE','DES_LATITUDE','DES_LONGITUDE','DAY_DE','WEEKDAY_DE',\n",
    "                    'WEEKEND_DE','HOUR_DE','HOUR_AR']]\n",
    "\n",
    "X_train, X_test= train_test_split(df_model1, test_size=0.3, stratify=df_model1.CANCELLED)\n",
    "\n",
    "y_train = X_train.CANCELLED\n",
    "y_test= X_test.CANCELLED\n",
    "\n",
    "X_train.drop(columns=['CANCELLED'], inplace=True)\n",
    "X_test.drop(columns=['CANCELLED'], inplace=True)\n",
    "\n",
    "#extract type of features\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "columns_order=np.array(numeric_features.tolist()+categorical_features.tolist())\n",
    "# apply encoders\n",
    "X_train,X_test,y_train, X_predict = encoders_cat(X_train,X_test,y_train,df_futurefd)\n",
    "\n",
    "# 2. Select features using Boruta\n",
    "feature_selector, selected_features = feature_selection(X_train, y_train, columns_order)\n",
    "\n",
    "# 3. Apply feature selection\n",
    "X_boruta= feature_selector.transform(np.array(X_train))\n",
    "X_test_boruta = feature_selector.transform(np.array(X_test)) \n",
    "\n",
    "# to run several model\n",
    "MLA = [\n",
    "    linear_model.LogisticRegression(random_state=11, max_iter=1000), \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    #SVM\n",
    "    svm.LinearSVC(random_state=11),\n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(random_state=11),\n",
    "    tree.ExtraTreeClassifier(random_state=11),\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(random_state=11),\n",
    "    ensemble.BaggingClassifier(random_state=11),\n",
    "    ensemble.GradientBoostingClassifier(random_state=11),\n",
    "    ensemble.RandomForestClassifier(n_jobs = -1,random_state=11),\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "MLA_columns = []\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "results=[]\n",
    "\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    cv_results = cross_val_score(alg, X_boruta, y_train, cv=10, scoring='f1')\n",
    "    results.append(cv_results)\n",
    "    predicted = alg.fit(X_boruta, y_train).predict(X_test_boruta)\n",
    "    fp, tp, th = roc_curve(y_test, predicted)\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'Train F1 Score'] = round(alg.score(X_boruta, y_train), 4)\n",
    "    print(\"model:\", alg,  \" Train F1 Score: \", round(alg.score(X_boruta, y_train), 4))\n",
    "    MLA_compare.loc[row_index, 'Test F1 Score'] = round(alg.score(X_test_boruta , y_test), 4)\n",
    "    print(\"model: \",alg,  \" Test F1 Score: \", round(alg.score(X_test_boruta , y_test), 4))\n",
    "    MLA_compare.loc[row_index, 'AUC'] = auc(fp, tp)  \n",
    "    row_index+=1\n",
    "    \n",
    "MLA_compare.sort_values(by = ['Test F1 Score'], ascending = False, inplace = True)    \n",
    "MLA_compare\n",
    "\n",
    "\n",
    "########################\n",
    "# Runing final modeling to have predictions and variable importance\n",
    "######################\n",
    "X_full= df_model1\n",
    "Y_full= X_full.ARRIVAL_DELAY_15M\n",
    "X_full.drop(columns=['ARRIVAL_DELAY_15M'], inplace=True)\n",
    "\n",
    "#extract type of features\n",
    "#numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "#categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "#columns_order=np.array(numeric_features.tolist()+categorical_features.tolist())\n",
    "#columns_order.shape\n",
    "\n",
    "# apply encoders\n",
    "X_full,Y_full= encoders_final_model(X_full,Y_full)\n",
    "\n",
    "# Apply feature selection\n",
    "X_full=feature_selector.transform(np.array(X_full)) \n",
    "X_predict=feature_selector.transform(np.array(X_predict)) \n",
    "\n",
    "#modeling \n",
    "model= ensemble.GradientBoostingClassifier(random_state=11)\n",
    "model.fit(X_full,Y_full)\n",
    "df_future['delay_15m_predClass']=model.predict(X_predict)\n",
    "probs=model.predict_proba(X_predict)\n",
    "df_future['delay_15m_predProbs=0']=probs[:,0]\n",
    "df_future['delay_15m_predProbs=1']=probs[:,1]\n",
    "\n",
    "#export prediction resutls\n",
    "df_future.to_excel('delay_15m_preditions.xlsx', engine='xlsxwriter')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
