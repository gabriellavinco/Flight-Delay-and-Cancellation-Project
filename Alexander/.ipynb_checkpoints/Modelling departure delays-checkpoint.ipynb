{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b02b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Apr 16 20:09:49 2022\n",
    "\n",
    "@author: asaines\n",
    "\"\"\"\n",
    "%run functions.ipynb\n",
    "#Set seed\n",
    "seed = 123\n",
    "#Import package / module for data\n",
    "import pandas as pd\n",
    "from seaborn import load_dataset\n",
    "import missingno as msno\n",
    "#Importing modules for Feature Engineering and modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler,StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import model_selection, linear_model, preprocessing, ensemble, neighbors, tree, impute, svm, metrics, decomposition\n",
    "from sklearn.metrics import accuracy_score,precision_score\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Loading data sets\n",
    "#data\n",
    "df_airports = pd.read_csv('airports.csv')\n",
    "df_airlines = pd.read_csv('airlines.csv')\n",
    "df_hdata = pd.read_csv('historic_data.csv', low_memory=False).sample(frac=0.01)\n",
    "df_future=pd.read_csv('future_data.csv', low_memory=False).sample(frac=0.01)\n",
    "#adding new features\n",
    "feat_hd, feat_fd=featureEngineering(df_hdata,df_future,df_airports )\n",
    "### MODEL: DELAY\n",
    "#dealing w/missing value \n",
    "#drop cancelled cases\n",
    "delay_hd=feat_hd[feat_hd.CANCELLED==0]\n",
    "delay_hd.drop(columns=['CANCELLED', 'CANCELLATION_REASON'], inplace=True)\n",
    "delay_hd=delay_hd[delay_hd.arrival_delay.isna()==False]\n",
    "# Check whether we have to deal with missing information in our dataset \n",
    "msno.matrix(delay_hd)\n",
    "# Provide the numerical representation of missingness\n",
    "miss = missingness(delay_hd)\n",
    "miss[miss.percentage > 0]\n",
    "# Based on this output we have an understanding of missingness \n",
    "#as well as an overview of the features for which we may consider imputation instead of dropping\n",
    "\n",
    "#Partition data\n",
    "delay_hd.drop(columns=['ARRIVAL_DELAY_15M'], inplace=True)\n",
    "x_train_feat, x_test_feat = train_test_split(delay_hd, test_size=0.3, stratify=delay_hd.DEPARTURE_DELAY_15M, random_state=1)\n",
    "y_train=x_train_feat.DEPARTURE_DELAY_15M\n",
    "y_test= x_test_feat.DEPARTURE_DELAY_15M\n",
    "\n",
    "###########\n",
    "# ENCODING##\n",
    "##############\n",
    "# Handling with missing values- columns transformers\n",
    "x_train,x_test= encoders(x_train_feat, x_test_feat)\n",
    "\n",
    "\n",
    "#Modelling departure delays using pipe, grid_search\n",
    "# imbalaced data - using ibmpipeline along with smote\n",
    "pipe_lr= imbpipeline(steps = [['over', SMOTE(random_state=11)],\n",
    "                               ['scaler', StandardScaler()],\n",
    "                                ['clf', LogisticRegression(random_state=11, max_iter=1000)]])\n",
    "\n",
    "# Construct grid_search\n",
    "stratified_kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=11)\n",
    "jobs = -1\n",
    "\n",
    "param_grid = {'clf__C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(estimator=pipe_lr,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='precision',\n",
    "                           cv=stratified_kfold,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(x_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "y_test_predict=grid_search.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980233d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e5aacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4e80a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
